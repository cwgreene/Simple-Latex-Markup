#1.6

p_0 = probability of heads not coming up.
This can only happen if the result is

 TT 

which has probabilty of w^2.

p_1 = probabilty of exactly one heads coming up
The combinations that will result in this are

 TH
 HT

which as a 2*w*u probabilty of occurring.

p_2 = probability of exactly two heads coming up

which can only happen with

 HH

this has probabilty of u^2 of occurring.

Since u^2=w^2, u = w (since all probabilities are positive). 
But this means that u^2=2*w*u=2*u^2, which menas u=w=0. This
is not possible since all possibilities must sum to 1. So
the three outcomes cannot have the same chance of occurring.


#1.7

(a)

The area, D, of a region of point value i, where i > 0, is

D(i) = pi( (6-i)^2 - (5-i)^2 ) * pi*r^2/5^2

So the probability function is

P(i) = { A - pi r^2	i = 0
       { D(i) / A	i != 0 


(b)

Given the board is hit, then we calculate

P(i|"Board Hit") = P(i)/P("Board Hit")

Since

P("Board Hit") = pi*r^2 / A

we obtain

P(i|"Board Hit") = (D(i)/A) /(pi*r^2/A) = D(i)/(pi*r^2)

this yields finally

P(i|"Board Hit") = ((6-i)^2 - (5-i)^2)/5^2

which is the same as the probability distribution of Example 1.2.7

#1.20
We note that this problem is equivalent to rolling a seven-sided die 12 times, and then
binning the results.

We note that certain bin combinations are not as likely as others, if we consider only 
the total number of calls in a given bin. This is because the binning process will take multiple
combinations of dice, and give them the same bin. So the number of die rolls is 7^12, but the
number of binnings is much less than that, which means they are not all equal probability. It is
easier to count everything if we work with objects that all have the same probabilty, so we operate
on the ordered combinations instead of the final binned results.

We define the following

 D^c_d = "Ways to distribute c marked calls across d days"
 1_D^c_d = "Ways to distribute c marked calls across d days, such that there is at least one call in each day"

We claim that

 |D^c_d| = \sum_{k=0}^{d} choose(d,k) |1_D^c_k|

That is, if consider the the ways to distribute across all days, it's going to be composed of all the sets
where we use all 7 days, plus the ones where use only 6 days (times seven since we have 7 days we which we
can opt not to use), plus the ones where we use only 5 days (times 7 choose 5), etc. 

This can be computed efficiently using dynamic tabling, evaluating the |1_D^c_1| and going upwards on the
total number of days. Alternatively, this can be accomplished by using memoization. Below is python code that
accomplishes this

%
%

#1.21
Consider the following sequence of selections, the first has 2n options,
but the second pick has 2n-2 options, one less shoe, and inabilty to select
the pair. So we have

2*n*(2*n-2)*(2*n-4)*...(2*n-2*2*r)

We can factor out 2, 2*r times. This yields

2^(2*r)*n!/(2*r)

Of course, the order doesn't matter ultimately, so we can divide out by
(n-2*r)!. This yields

( n )
(2*r)*(2^(2*r))

And then, to obtain the probability, we divide out by all possible ways of
picking 2*r shoes from 2*n shoes. This yields

(n 2*r) *2^(2*r)/(2*n 2*r)

#1.29

#1.36
This is the complement of not hitting it at least twice, which is the
sum of 

~P(x) = (4/5)^9*(1/5)(10 1) + (1/5)^10

So P(x) = 1-~P(x).

If it is hit at least once, than again, it is the complement, but
we rule out the situation where it is never hit. So the probability is

P(x) = (10 1) * (1/5)^9


